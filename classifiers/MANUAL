## Authors: Yanyu Liang, Zhishen Cao, Raghunandan Avula
## Computational Biology Department
## Carnegie Mellon University 
## 5000 Forbes Ave, Pittsburgh, PA 15213
## yanyul OR zhishenc OR ravula@andrew.cmu.edu 

DESCRIPTIONS
This folder contains a software, tts_prediction, that predicts transcription termination sites in Maize (and it is also applicable for other species by using customized motifs and re-trained classifier).

tts_prediction computes features from a fixed size of genome scanning window, where there are three feature categories, (di)nucleotide frequency, motif occurence, and transcript local secondary structure and feeds these features into support vector machine with optimized kernel for Maize (if you want to apply it for other species, see EXTENSION for more details) 

DENPENDENCIES
To use tts_prediction, you need Python packages: sklearn, numpy, matplotlib and Bio

INSTALL
> source setup # it install all dependencies and source the Python library used by tts_prediction
> ./test.sh  # test if tts_prediction runs correctly  

USAGE
1. Print the usage of tts_predction
> python tts_prediction.py
USAGE:
python tts_prediction.py [classifier] [genome] [motif_path] [jump_size] [out]
for example:
[classifier]: test_classifier
[genome]: ./genome/test_genome.fa
[motif_path]: ./motifs
[jump_size]: 100

[jump_size] indicates the size you jump when scanning the genome. jump_size = 1 means that you take a look at every base pair on the genome, and for jump_size > 1, you will skip jump_size - 1 base pairs in between. 
[out] indicates the output file name, and here the output format is BED, which gives the positions of predicted terminator sites. 
[classifier] needs the name of classifier, which can either be the one we provide or any other classifiers trained by the training scripts we provide.

2. Run an example: use test_classifier as classifier and predict the TTS in test_genome.fa. "motifs/" indicates the path of motifs used by classifier
> python tts_prediction.py test_classifier genome/test_genome.fa motifs/ 1 test.bed 



EXTENSION
In this section, we talk about the usage of training scripts.
1. The input for training is two-column file: [label]SPACE[sequence]
Here label = 1 indicates TTS, and 2 indicates negative ones.
To convert FASTA into the input format compatible for our scripts, check lib/fasta2data.py
Additionally, we cannot accept "N" in training sequences (in genome, they will be ignore automatically), check lib/foo.py to clean you data (the input should be in our format already). 


2. The list of training scripts at lib/:
	train_boost_tree.py 		# train a Boost-of-Trees classifier
	train_svm_rbf.py   			# train a SVM wih RBF kernel
	train_svm_linear.py      	# train a SVM with Linear kernel
	train_tree.py 				# train a Random Forest classifier

The usage of them is the same. Let's take train_svm_rbf.py as an example:

a. Print the help page:
> python lib/train_svm_rbf.py 
USAGE:
python lib/train_svm_rbf.py [training_set] [motif_path] [save_classifier_as] [output_report]
for example:
[training_set]: training.data
[motif_path]: ./motifs

[save_classifier_as] takes a string that will become the prefix of the newly trained classifier.
[output_report], the training accuracy and a summary of the parameters of the classifer will be printed to [output_report]
The script will print the confusion matrix to STDOUT.

b. Train a classifier:
> python lib/train_svm_rbf.py training_datasets/test_test.txt motifs test test.out
    1   2   true
1  [23, 3]
2  [27, 47]
predict
accuracy = 0.7

> cat test.out
training accuracy = 0.7 
### classifer info ###
kernel	rbf
C	100
verbose	False
probability	False
degree	3
shrinking	True
max_iter	-1
decision_function_shape	None
random_state	None
tol	0.001
cache_size	200
coef0	0.0
gamma	0.0001
class_weight	None

c. Use customized features or classifier parameters in training scripts:
In principle, you can select a set of features that you want to incorporate into your classifier by comment/uncommenting the following lines:
	feature_gen.add_function('XXX', PARAMETERS)
	my_classifier = lib_classifier.My_Classifier(feature_gen, CLASSIFIER_NAME, PARAMETERS, path)

You can even modify the PARAMETERS. But till now, these spaces are not well-documented, so it is not recommended.

d. Use tts_prediction_train.py to play with classifiers and features:
tts_prediction_train.py is a script that takes a training set and test set and train a classifier on training set, also report its test accuracy. Take a look at the script, it shows the general step of training inside all training scripts. But different from training script, its main function is to quickly report test error which might be helpful for feature selection or model selection. Additionally, it outputs two CSV files train.csv and test.csv that contains the design matrix generated by the features you use, which might be helpful if you want to use other softwares for feature selection. The information of every column is printed to STDOUT directly.

The usage of tts_prediction_train.py:
> python tts_prediction_train.py 
Program for discovering TTSs in Maize Genome
tts_prediction_train is for training the model, please use tts_prediction for predicting the sites

USAGE:
python tts_prediction_train.py [training_set] [test_set] [motif_path] [save_or_not] [save_name_if_save]

if you want to save your classifier, type 'save' at [save_or_not] and fill in the classifier name to save as
classifier is saved in three files: XXX.cls, XXX.features and XXX.classifier

for example:
[training_set]: training.data
[test_set]: test.data
[motif_path]: ./motifs
[save_or_not]: save
[save_name_if_save]: XXX

[save_or_not], you can save the classifier only when you type 'save'

Run an example:
> python tts_prediction_train.py training_datasets/test_training.txt training_datasets/test_test.txt motifs save tts_pre
[[0, 10], [10, 11], [11, 12], [12, 13], [13, 14], [14, 15], [15, 71], [71, 151], [151, 231], [231, 311], [311, 391], [391, 471], [471, 474]]
['gc_content', 'motif_score', 'motif_score', 'motif_score', 'motif_score'i, 'motif_score', 'rna_struct', 'motif_struct_pair', 'motif_struct_pair', 'motif_struct_pair', 'motif_struct_pair', 'motif_struct_pair', 'struct_energy']
[[0, 10], [10, 11], [11, 12], [12, 13], [13, 14], [14, 15], [15, 71], [71, 151], [151, 231], [231, 311], [311, 391], [391, 471], [471, 474]]
['gc_content', 'motif_score', 'motif_score', 'motif_score', 'motif_score', 'motif_score', 'rna_struct', 'motif_struct_pair', 'motif_struct_pair', 'motif_struct_pair', 'motif_struct_pair', 'motif_struct_pair', 'struct_energy']
    1   2   true
1  [41, 22]
2  [9, 28]
predict

The summary of available classifiers is the following:
'svm' : SVM
'tree' : Random Forest
'centroid' : Nearest Centroid
'logistic' : Logistic Regression
'boost' : AdaBoost with Decision Tree

PARAMETERS for classifiers:
'svm' : [C, gamma, kernel], where kernel = 'rbf'/'linear'/'sigmoid'/'poly'/'rbf_linear_structural_motif_sim' (if choose 'rbf_linear_structural_motif_sim', you need to add another parameter (integer) at the end for the inside RBF kernel)
'tree' : [n_estimators]
'centroid' : []
'logistic' : [C, penalty]
'boost' : [n_estimators]

The summary of available feature functions:
'gc_content' : the GC content inside the window by selected bins
'motif_score' : score of the given motifs for each substring or take to top score inside the window
'rna_struct' : secondary structure for a given length of very middle substring
'motif_struct_pair' : score of motifs which are calculated for predicted loop and stem respectively
'struct_energy' : the folding energy of a given length of very middle substring

PARAMETERS for feature functions:
'gc_content' : N (number of bins)
'motif_score' : [motif_file_name, options] (option = '-b' will use only best score; otherwise use all the scores)
'rna_struct' : [width, mode] (width indicates how long is the substring you want to use for structure prediction; mode = '-up' only uses the upstream side of structure, otherwise use both upstream and downstream and will also predict the structure when upstream part and downstream part are taken as a whole) 
'motif_struct_pair' : [motif, width] (width indicates the length of substring you want to take into consideration)
'struct_energy' : [width, mode] (mode option is the same as 'rna_struct')






